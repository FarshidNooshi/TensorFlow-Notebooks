{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30350af2",
   "metadata": {},
   "source": [
    "# Week 2: Predicting time series\n",
    "\n",
    "Welcome! In the previous assignment you got some exposure to working with time series data, but you didn't use machine learning techniques for your forecasts. This week you will be using a deep neural network to create forecasts to see how this technique compares with the ones you already tried out. Once again all of the data is going to be generated.\n",
    "\n",
    "Let's get started!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ea662d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BOjujz601HcS",
    "outputId": "21a00a04-e660-4eb1-dc6f-8ad3741dee5a"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from dataclasses import dataclass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00897401",
   "metadata": {},
   "source": [
    "## Generating the data\n",
    "\n",
    "\n",
    "The next cell includes a bunch of helper functions to generate and plot the time series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79cd826a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_series(time, series, format=\"-\", start=0, end=None):\n",
    "    plt.plot(time[start:end], series[start:end], format)\n",
    "    plt.xlabel(\"Time\")\n",
    "    plt.ylabel(\"Value\")\n",
    "    plt.grid(False)\n",
    "\n",
    "def trend(time, slope=0):\n",
    "    return slope * time\n",
    "\n",
    "def seasonal_pattern(season_time):\n",
    "    \"\"\"Just an arbitrary pattern, you can change it if you wish\"\"\"\n",
    "    return np.where(season_time < 0.1,\n",
    "                    np.cos(season_time * 6 * np.pi), \n",
    "                    2 / np.exp(9 * season_time))\n",
    "\n",
    "def seasonality(time, period, amplitude=1, phase=0):\n",
    "    \"\"\"Repeats the same pattern at each period\"\"\"\n",
    "    season_time = ((time + phase) % period) / period\n",
    "    return amplitude * seasonal_pattern(season_time)\n",
    "\n",
    "def noise(time, noise_level=1, seed=None):\n",
    "    rnd = np.random.RandomState(seed)\n",
    "    return rnd.randn(len(time)) * noise_level"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2512591c",
   "metadata": {},
   "source": [
    "You will be generating time series data that greatly resembles the one from last week but with some differences.\n",
    "\n",
    "**Notice that this time all the generation is done within a function and global variables are saved within a dataclass. This is done to avoid using global scope as it was done in during the previous week.**\n",
    "\n",
    "If you haven't used dataclasses before, they are just Python classes that provide a convenient syntax for storing data. You can read more about them in the [docs](https://docs.python.org/3/library/dataclasses.html). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d63bd1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_time_series():\n",
    "    # The time dimension or the x-coordinate of the time series\n",
    "    time = np.arange(4 * 365 + 1, dtype=\"float32\")\n",
    "\n",
    "    # Initial series is just a straight line with a y-intercept\n",
    "    y_intercept = 10\n",
    "    slope = 0.005\n",
    "    series = trend(time, slope) + y_intercept\n",
    "\n",
    "    # Adding seasonality\n",
    "    amplitude = 50\n",
    "    series += seasonality(time, period=365, amplitude=amplitude)\n",
    "\n",
    "    # Adding some noise\n",
    "    noise_level = 3\n",
    "    series += noise(time, noise_level, seed=51)\n",
    "    \n",
    "    return time, series\n",
    "\n",
    "\n",
    "# Save all \"global\" variables within the G class (G stands for global)\n",
    "@dataclass\n",
    "class G:\n",
    "    TIME, SERIES = generate_time_series()\n",
    "    SPLIT_TIME = 1100\n",
    "    WINDOW_SIZE = 20\n",
    "    BATCH_SIZE = 32\n",
    "    SHUFFLE_BUFFER_SIZE = 1000\n",
    "    \n",
    "\n",
    "# Plot the generated series\n",
    "plt.figure(figsize=(10, 6))\n",
    "plot_series(G.TIME, G.SERIES)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5acb315b",
   "metadata": {},
   "source": [
    "## Splitting the data\n",
    "\n",
    "Since you already coded the `train_val_split` function during last week's assignment, this time it is provided for you:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5dcbfa",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 645
    },
    "id": "Zswl7jRtGzkk",
    "outputId": "acfe857a-4a0f-4d41-bd45-1df7fa26f4d0"
   },
   "outputs": [],
   "source": [
    "def train_val_split(time, series, time_step=G.SPLIT_TIME):\n",
    "\n",
    "    time_train = time[:time_step]\n",
    "    series_train = series[:time_step]\n",
    "    time_valid = time[time_step:]\n",
    "    series_valid = series[time_step:]\n",
    "\n",
    "    return time_train, series_train, time_valid, series_valid\n",
    "\n",
    "\n",
    "# Split the dataset\n",
    "time_train, series_train, time_valid, series_valid = train_val_split(G.TIME, G.SERIES)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0709eaf",
   "metadata": {},
   "source": [
    "## Processing the data\n",
    "\n",
    "As you saw on the lectures you can feed the data for training by creating a dataset with the appropiate processing steps such as `windowing`, `flattening`, `batching` and `shuffling`. To do so complete the `windowed_dataset` function below.\n",
    "\n",
    "Notice that this function receives a `series`, `window_size`, `batch_size` and `shuffle_buffer` and the last three of these default to the \"global\" values defined earlier.\n",
    "\n",
    "Be sure to check out the [docs](https://www.tensorflow.org/api_docs/python/tf/data/Dataset) about `TF Datasets` if you need any help."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b53b59",
   "metadata": {
    "id": "4sTTIOCbyShY"
   },
   "outputs": [],
   "source": [
    "def windowed_dataset(series, window_size=G.WINDOW_SIZE, batch_size=G.BATCH_SIZE, shuffle_buffer=G.SHUFFLE_BUFFER_SIZE):\n",
    "    \n",
    "    ### START CODE HERE\n",
    "    \n",
    "    # Create dataset from the series\n",
    "    dataset = None\n",
    "    \n",
    "    # Slice the dataset into the appropriate windows\n",
    "    dataset = None\n",
    "    \n",
    "    # Flatten the dataset\n",
    "    dataset = None\n",
    "    \n",
    "    # Shuffle it\n",
    "    dataset = None\n",
    "    \n",
    "    # Split it into the features and labels\n",
    "    dataset = None\n",
    "    \n",
    "    # Batch it\n",
    "    dataset = None\n",
    "    \n",
    "    ### END CODE HERE\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "237af965",
   "metadata": {},
   "source": [
    "To test your function you will be using a `window_size` of 1 which means that you will use each value to predict the next one. This for 5 elements since a `batch_size` of 5 is used and no shuffle since `shuffle_buffer` is set to 1.\n",
    "\n",
    "Given this, the batch of features should be identical to the first 5 elements of the `series_train` and the batch of labels should be equal to elements 2 through 6 of the `series_train`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8019711b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test your function with windows size of 1 and no shuffling\n",
    "test_dataset = windowed_dataset(series_train, window_size=1, batch_size=5, shuffle_buffer=1)\n",
    "\n",
    "# Get the first batch of the test dataset\n",
    "batch_of_features, batch_of_labels = next((iter(test_dataset)))\n",
    "\n",
    "print(f\"batch_of_features has type: {type(batch_of_features)}\\n\")\n",
    "print(f\"batch_of_labels has type: {type(batch_of_labels)}\\n\")\n",
    "print(f\"batch_of_features has shape: {batch_of_features.shape}\\n\")\n",
    "print(f\"batch_of_labels has shape: {batch_of_labels.shape}\\n\")\n",
    "print(f\"batch_of_features is equal to first five elements in the series: {np.allclose(batch_of_features.numpy().flatten(), series_train[:5])}\\n\")\n",
    "print(f\"batch_of_labels is equal to first five labels: {np.allclose(batch_of_labels.numpy(), series_train[1:6])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85eeebe7",
   "metadata": {},
   "source": [
    "**Expected Output:**\n",
    "\n",
    "```\n",
    "batch_of_features has type: <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
    "\n",
    "batch_of_labels has type: <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
    "\n",
    "batch_of_features has shape: (5, 1)\n",
    "\n",
    "batch_of_labels has shape: (5,)\n",
    "\n",
    "batch_of_features is equal to first five elements in the series: True\n",
    "\n",
    "batch_of_labels is equal to first five labels: True\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e4dc813",
   "metadata": {},
   "source": [
    "## Defining the model architecture\n",
    "\n",
    "Now that you have a function that will process the data before it is fed into your neural network for training, it is time to define you layer architecture.\n",
    "\n",
    "Complete the `create_model` function below. Notice that this function receives the `window_size` since this will be an important parameter for the first layer of your network.\n",
    "\n",
    "Hint:\n",
    "- You will only need `Dense` layers.\n",
    "- The training should be really quick so if you notice that each epoch is taking more than a few seconds, consider trying a different architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b40dc9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TW-vT7eLYAdb",
    "outputId": "94611183-4107-4062-cefd-c79d902d4e2f"
   },
   "outputs": [],
   "source": [
    "def create_model(window_size=G.WINDOW_SIZE):\n",
    "\n",
    "    ### START CODE HERE\n",
    "\n",
    "    model = tf.keras.models.Sequential([ \n",
    "        \n",
    "    ]) \n",
    "\n",
    "    model.compile(loss=None,\n",
    "                  optimizer=None)\n",
    "    \n",
    "    ### END CODE HERE\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f836133",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the processing to the whole training series\n",
    "dataset = windowed_dataset(series_train)\n",
    "\n",
    "# Save an instance of the model\n",
    "model = create_model()\n",
    "\n",
    "# Train it\n",
    "model.fit(dataset, epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e83ea16",
   "metadata": {},
   "source": [
    "## Evaluating the forecast\n",
    "\n",
    "Now it is time to evaluate the performance of the forecast. For this you can use the `compute_metrics` function that you coded in the previous assignment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab3740d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(true_series, forecast):\n",
    "    \n",
    "    mse = tf.keras.metrics.mean_squared_error(true_series, forecast).numpy()\n",
    "    mae = tf.keras.metrics.mean_absolute_error(true_series, forecast).numpy()\n",
    "\n",
    "    return mse, mae"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff588f4",
   "metadata": {},
   "source": [
    "At this point only the model that will perform the forecast is ready but you still need to compute the actual forecast. \n",
    "\n",
    "For this, run the cell below which uses the `generate_forecast` function to compute the forecast. This function generates the next value given a set of the previous `window_size` points for every point in the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7608d29d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 388
    },
    "id": "efhco2rYyIFF",
    "outputId": "3ee47e36-7681-4d6b-9c9c-ad73883c3fda"
   },
   "outputs": [],
   "source": [
    "def generate_forecast(series=G.SERIES, split_time=G.SPLIT_TIME, window_size=G.WINDOW_SIZE):\n",
    "    forecast = []\n",
    "    for time in range(len(series) - window_size):\n",
    "        forecast.append(model.predict(series[time:time + window_size][np.newaxis]))\n",
    "\n",
    "    forecast = forecast[split_time-window_size:]\n",
    "    results = np.array(forecast)[:, 0, 0]\n",
    "    return results\n",
    "\n",
    "\n",
    "# Save the forecast\n",
    "dnn_forecast = generate_forecast()\n",
    "\n",
    "# Plot it\n",
    "plt.figure(figsize=(10, 6))\n",
    "plot_series(time_valid, series_valid)\n",
    "plot_series(time_valid, dnn_forecast)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fbf5678",
   "metadata": {},
   "source": [
    "**Expected Output:**\n",
    "\n",
    "A series similar to this one:\n",
    "\n",
    "<div>\n",
    "<img src=\"images/forecast.png\" width=\"500\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96085ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse, mae = compute_metrics(series_valid, dnn_forecast)\n",
    "\n",
    "print(f\"mse: {mse:.2f}, mae: {mae:.2f} for forecast\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8275d537",
   "metadata": {},
   "source": [
    "**To pass this assignment your forecast should achieve an MSE of 30 or less.**\n",
    "\n",
    "- If your forecast didn't achieve this threshold try re-training your model with a different architecture or tweaking the optimizer's parameters.\n",
    "\n",
    "\n",
    "- If your forecast did achieve this threshold run the following cell to save your model in a HDF5 file file which will be used for grading and after doing so, submit your assigment for grading.\n",
    "\n",
    "\n",
    "- This environment includes a dummy `my_model.h5` file which is just a dummy model trained for one epoch. **To replace this file with your actual model you need to run the next cell before submitting for grading.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe76ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save your model in HDF5 format\n",
    "model.save('my_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a42cdc",
   "metadata": {},
   "source": [
    "**Congratulations on finishing this week's assignment!**\n",
    "\n",
    "You have successfully implemented a neural network capable of forecasting time series while also learning how to leverage Tensorflow's Dataset class to process time series data!\n",
    "\n",
    "**Keep it up!**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
